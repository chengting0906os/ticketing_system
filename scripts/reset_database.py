#!/usr/bin/env python3
"""
Database Reset Script
å®Œæ•´é‡ç½® PostgreSQL è³‡æ–™åº«

åŠŸèƒ½ï¼š
1. Drop & Recreate Database - å®Œå…¨æ¸…ç©ºè³‡æ–™åº«
2. Run Alembic Migrations - å»ºç«‹æœ€æ–°çš„ schema
3. Create Initial Users - å‰µå»ºæ¸¬è©¦ç”¨ seller å’Œ buyer
4. Create Initial Event - å‰µå»ºæ´»å‹•ä¸¦ç™¼é€åº§ä½åˆå§‹åŒ–åˆ° Kafka (â†’ seat_reservation Kvrocks)

æ³¨æ„ï¼š
- æ­¤è…³æœ¬æœƒè§¸ç™¼åº§ä½åˆå§‹åŒ–æ¶ˆæ¯ï¼Œéœ€è¦ seat_reservation_mq_consumer é‹è¡Œä¸­
- åº§ä½è³‡æ–™æœƒå­˜å…¥ seat_reservation çš„ Kvrocks (ä¸æ˜¯ PostgreSQL)
- ç¥¨åˆ¸è³‡æ–™æœƒå­˜å…¥ event_ticketing çš„ PostgreSQL
"""
import subprocess
import os
from src.shared.constant.path import BASE_DIR
import asyncio
import time
from sqlalchemy import create_engine, text

from src.shared.config.db_setting import Base

from src.booking.infra.booking_model import BookingModel, BookingTicketModel  # noqa: F401
from src.event_ticketing.infra.event_model import EventModel  # noqa: F401
from src.event_ticketing.infra.ticket_model import TicketModel  # noqa: F401
from src.shared_kernel.user.infra.user_model import UserModel  # noqa: F401

from src.event_ticketing.use_case.command.create_event_use_case import CreateEventUseCase
from src.event_ticketing.infra.event_ticketing_command_repo_impl import EventTicketingCommandRepoImpl
from src.shared.config.db_setting import async_session_maker
from src.shared_kernel.user.domain.user_entity import UserEntity, UserRole
from src.shared_kernel.user.infra.bcrypt_password_hasher import BcryptPasswordHasher
from src.shared_kernel.user.infra.user_command_repo_impl import UserCommandRepoImpl
from src.shared.config.core_setting import settings
from src.shared_infra.message_queue.kafka_config_service import KafkaConfigService
from scripts.seating_config import SEATING_CONFIG_50000, SEATING_CONFIG_30
from contextlib import asynccontextmanager


def get_database_url() -> str:
    """å–å¾—è³‡æ–™åº«é€£æ¥ URL"""

    return settings.DATABASE_URL_ASYNC


async def drop_and_recreate_database():
    """å®Œå…¨åˆªé™¤ä¸¦é‡æ–°å‰µå»ºè³‡æ–™åº«"""
    database_url = get_database_url()
    print(f"Database URL: {database_url}")

    # è§£æè³‡æ–™åº«é€£æ¥ä¿¡æ¯
    if database_url.startswith('postgresql+asyncpg://'):
        sync_url = database_url.replace('postgresql+asyncpg://', 'postgresql://')
    else:
        sync_url = database_url

    # æå–è³‡æ–™åº«åç¨±
    db_name = sync_url.split('/')[-1]
    server_url = sync_url.rsplit('/', 1)[0]

    print(f"Server URL: {server_url}")
    print(f"Database name: {db_name}")

    try:
        print("ğŸ—‘ï¸ Dropping database...")

        # é€£æ¥åˆ° postgres é è¨­è³‡æ–™åº«ä»¥åŸ·è¡Œ DROP/CREATE
        admin_engine = create_engine(f"{server_url}/postgres", isolation_level="AUTOCOMMIT")

        with admin_engine.connect() as conn:
            # é—œé–‰ç¾æœ‰é€£æ¥
            conn.execute(text(f"""
                SELECT pg_terminate_backend(pid)
                FROM pg_stat_activity
                WHERE datname = '{db_name}' AND pid <> pg_backend_pid();
            """))

            # åˆªé™¤è³‡æ–™åº«
            conn.execute(text(f"DROP DATABASE IF EXISTS {db_name};"))
            print(f"   âœ… Database '{db_name}' dropped")

            # ç­‰å¾…ä¸€ä¸‹ç¢ºä¿å®Œå…¨æ¸…ç†
            
            time.sleep(1)

            # é‡æ–°å‰µå»ºè³‡æ–™åº«
            conn.execute(text(f"CREATE DATABASE {db_name};"))
            print(f"   âœ… Database '{db_name}' created")

            # ç­‰å¾…ç¢ºä¿è³‡æ–™åº«å®Œå…¨å‰µå»º
            time.sleep(1)

        admin_engine.dispose()

        print("ğŸ—ï¸ Running database migrations...")

        # ç¢ºä¿æ²’æœ‰æ‡‰ç”¨ç¨‹å¼é‹è¡Œä¾†é¿å…è‡ªå‹•è¡¨å‰µå»º
        print("   â¸ï¸ Ensuring no FastAPI app is running during migration...")

        # é‹è¡Œ Alembic é·ç§»
        

        # è¨­ç½®ç’°å¢ƒè®Šé‡é˜²æ­¢ SQLAlchemy è‡ªå‹•å‰µå»ºè¡¨
        env = os.environ.copy()
        env['SKIP_DB_INIT'] = 'true'

        # é¦–å…ˆæª¢æŸ¥è³‡æ–™åº«æ˜¯å¦çœŸçš„æ˜¯ç©ºçš„
        print("   ğŸ” Verifying database is empty...")
        table_count = 0
        check_engine = create_engine(sync_url)
        try:
            with check_engine.connect() as conn:
                result = conn.execute(text("""
                    SELECT count(*) FROM information_schema.tables
                    WHERE table_schema = 'public'
                """))
                table_count = result.scalar() or 0
                print(f"   ğŸ“Š Found {table_count} existing tables")

                if table_count > 0:
                    print("   ğŸ§¹ Database not empty, recreating it again...")
        finally:
            check_engine.dispose()

        # å¦‚æœéœ€è¦é‡æ–°å‰µå»ºï¼Œåœ¨å¤–é¢åŸ·è¡Œä»¥é¿å…é€£æ¥å•é¡Œ
        if table_count > 0:
            # é‡æ–°å‰µå»ºè³‡æ–™åº«ç¢ºä¿å®Œå…¨ä¹¾æ·¨
            admin_engine = create_engine(f"{server_url}/postgres", isolation_level="AUTOCOMMIT")
            try:
                with admin_engine.connect() as admin_conn:
                    admin_conn.execute(text(f"""
                        SELECT pg_terminate_backend(pid)
                        FROM pg_stat_activity
                        WHERE datname = '{db_name}' AND pid <> pg_backend_pid();
                    """))
                    admin_conn.execute(text(f"DROP DATABASE IF EXISTS {db_name};"))
                    time.sleep(1)
                    admin_conn.execute(text(f"CREATE DATABASE {db_name};"))
                    time.sleep(1)
            finally:
                admin_engine.dispose()

            print("   âœ… Database recreated and verified empty")

        # é‹è¡Œ alembic upgrade head (alembic.ini åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„)
        print("   ğŸ”„ Running 'alembic upgrade head'...")
        result = subprocess.run(
            ['alembic', 'upgrade', 'head'],
            cwd=BASE_DIR,
            capture_output=True,
            text=True,
            env=env
        )

        if result.returncode == 0:
            print("   âœ… Database migrations completed")
            if result.stdout:
                print(f"   ğŸ“‹ Output: {result.stdout.strip()}")
        else:
            print(f"   âŒ Migration failed (return code: {result.returncode})")
            if result.stdout:
                print(f"   ğŸ“‹ STDOUT: {result.stdout}")
            if result.stderr:
                print(f"   ğŸ“‹ STDERR: {result.stderr}")
            raise Exception(f"Alembic migration failed with return code {result.returncode}")

        print("Database recreation completed!")

    except Exception as e:
        print(f"âŒ Failed to recreate database: {e}")
        raise


async def create_init_users_in_session(session):
        try:
            print("Creating initial users...")

            # å‰µå»ºä¸€å€‹ä½¿ç”¨ç•¶å‰ session çš„ repo


            @asynccontextmanager
            async def get_current_user_session():
                yield session

            user_repo = UserCommandRepoImpl(lambda: get_current_user_session())
            password_hasher = BcryptPasswordHasher()

            seller = UserEntity(
                email="s@t.com",
                name="init seller",
                role=UserRole.SELLER,
                is_active=True,
                is_superuser=False,
                is_verified=True
            )
            seller.set_password("P@ssw0rd", password_hasher)
            created_seller = await user_repo.create(seller)
            print(f"   Created seller: ID={created_seller.id}, Email={created_seller.email}")

            buyer = UserEntity(
                email="b@t.com",
                name="init buyer",
                role=UserRole.BUYER,
                is_active=True,
                is_superuser=False,
                is_verified=True
            )
            buyer.set_password("P@ssw0rd", password_hasher)
            created_buyer = await user_repo.create(buyer)
            print(f"   Created buyer: ID={created_buyer.id}, Email={created_buyer.email}")

            # Note: commit will be handled by main() function
            print("Initial users created!")
            return created_seller.id

        except Exception as e:
            print(f"Failed to create users: {e}")
            raise


async def create_init_event_in_session(session, seller_id: int):
        try:
            # èª¿è©¦ï¼šç¢ºèªç”¨æˆ¶æ˜¯å¦å­˜åœ¨æ–¼æ•¸æ“šåº«ä¸­
            from sqlalchemy import text
            result = await session.execute(text(f'SELECT id, email FROM "user" WHERE id = {seller_id}'))
            user_check = result.fetchone()
            if user_check:
                print(f"   ğŸ” User found in DB: ID={user_check[0]}, Email={user_check[1]}")
            else:
                print(f"   âŒ User {seller_id} NOT found in database!")
                return None

            @asynccontextmanager
            async def get_current_session():
                yield session

            event_ticketing_repo = EventTicketingCommandRepoImpl(lambda: get_current_session())
            kafka_config = KafkaConfigService()

            # å‰µå»º UseCase
            create_event_use_case = CreateEventUseCase(
                session=session,
                event_ticketing_command_repo=event_ticketing_repo,
                kafka_service=kafka_config
            )

            # åº§ä½é…ç½®é¸æ“‡
            # SEATING_CONFIG_30: é–‹ç™¼æ¸¬è©¦ç”¨ï¼ˆ30 å€‹åº§ä½ï¼Œå¿«é€Ÿåˆå§‹åŒ–ï¼‰
            # SEATING_CONFIG_50000: ç”Ÿç”¢ç’°å¢ƒç”¨ï¼ˆ50,000 å€‹åº§ä½ï¼Œå®Œæ•´å£“åŠ›æ¸¬è©¦ï¼‰
            seating_config = SEATING_CONFIG_50000  # é–‹ç™¼æ¨¡å¼é è¨­ä½¿ç”¨å°è¦æ¨¡é…ç½®

            # Calculate total seats from nested structure: sections â†’ subsections â†’ rows Ã— seats_per_row
            total_seats = sum(
                subsection['rows'] * subsection['seats_per_row']
                for section in seating_config['sections']
                for subsection in section['subsections']
            )

            # ä½¿ç”¨ UseCase çš„ create_event_and_tickets æ–¹æ³•
            # é€™æœƒç™¼é€åº§ä½åˆå§‹åŒ–æ¶ˆæ¯åˆ° Kafka â†’ seat_reservation_mq_consumer â†’ Kvrocks
            event_aggregate = await create_event_use_case.create_event_and_tickets(
                name="Concert Event",
                description="Amazing live music performance",
                seller_id=seller_id,
                venue_name="Taipei Arena",
                seating_config=seating_config,
                is_active=True,
            )

            event = event_aggregate.event
            tickets = event_aggregate.tickets

            print(f"   âœ… Created event: ID={event.id}, Name={event.name}")
            print(f"   âœ… Created tickets: {len(tickets)}")
            print(f"   ğŸš€ Event created successfully via UseCase")

            print("âœ¨ Initial event and tickets created using CreateEventUseCase!")
            return event.id

        except Exception as e:
            print(f"âŒ Failed to create event: {e}")
            raise


async def verify_data():
    async with async_session_maker() as session:
        try:
            print("Verifying data...")

            result = await session.execute(text('SELECT COUNT(*) FROM "user"'))
            user_count = result.scalar()
            print(f"   User count: {user_count}")

            result = await session.execute(text('SELECT COUNT(*) FROM event'))
            event_count = result.scalar()
            print(f"   Event count: {event_count}")

            result = await session.execute(text('SELECT COUNT(*) FROM ticket'))
            ticket_count = result.scalar()
            print(f"   Ticket count: {ticket_count}")

            result = await session.execute(text('SELECT id, email, role FROM "user" ORDER BY id'))
            users = result.fetchall()
            for user in users:
                print(f"      User ID={user[0]}, Email={user[1]}, Role={user[2]}")

            result = await session.execute(text('SELECT id, name, seller_id FROM event'))
            events = result.fetchall()
            for event in events:
                print(f"      Event ID={event[0]}, Name={event[1]}, Seller={event[2]}")

            print("Data verification completed!")

        except Exception as e:
            print(f"Failed to verify data: {e}")


async def flush_kvrocks():
    """æ¸…ç©º Kvrocks æ‰€æœ‰è³‡æ–™"""
    try:
        import redis.asyncio as aioredis

        print("ğŸ—‘ï¸  Flushing Kvrocks...")
        client = await aioredis.from_url(
            f"redis://{settings.KVROCKS_HOST}:{settings.KVROCKS_PORT}/{settings.KVROCKS_DB}",
            password=settings.KVROCKS_PASSWORD if settings.KVROCKS_PASSWORD else None,
            decode_responses=True,
        )

        # æ¸…ç©ºæ‰€æœ‰è³‡æ–™
        await client.flushdb()
        await client.close()

        print("âœ… Kvrocks flushed successfully!")

    except Exception as e:
        print(f"âš ï¸  Failed to flush Kvrocks (non-critical): {e}")
        print("    Kvrocks may not be running, continuing anyway...")


async def main():
    print("Starting database reset...")
    print("=" * 50)

    try:
        await drop_and_recreate_database()
        print()

        await flush_kvrocks()
        print()

        # ä½¿ç”¨å–®ä¸€ session ä¾†è™•ç†æ‰€æœ‰æ•¸æ“šæ“ä½œ
        async with async_session_maker() as session:
            try:
                seller_id = await create_init_users_in_session(session)
                print()

                await create_init_event_in_session(session, seller_id) # type: ignore
                print()

                # ä¸€æ¬¡æ€§æäº¤æ‰€æœ‰æ“ä½œ
                await session.commit()
                print("âœ… All data operations committed successfully!")

            except Exception as e:
                await session.rollback()
                print(f"âŒ Rolling back all operations: {e}")
                raise

        await verify_data()
        print()

        print("=" * 50)
        print("Database reset completed!")
        print("Test accounts:")
        print("   Seller: s@t.com / P@ssw0rd")
        print("   Buyer:  b@t.com / P@ssw0rd")

    except Exception as e:
        print(f"Reset failed: {e}")
        exit(1)


if __name__ == "__main__":
    asyncio.run(main())
