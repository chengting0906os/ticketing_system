"""
Create Event Use Case - ä½¿ç”¨æ–°çš„ EventTicketingAggregate

é‡æ§‹å¾Œçš„æ´»å‹•å‰µå»ºæ¥­å‹™é‚è¼¯ï¼š
- ä½¿ç”¨ EventTicketingAggregate ä½œç‚ºèšåˆæ ¹
- æ•´åˆæ´»å‹•å’Œç¥¨å‹™å‰µå»ºé‚è¼¯
- è² è²¬ Kafka åŸºç¤è¨­æ–½åˆå§‹åŒ–
- è™•ç† RocksDB åº§ä½åˆå§‹åŒ–
"""

import asyncio
import os
from typing import Dict

from dependency_injector.wiring import Provide, inject
from fastapi import Depends
from sqlalchemy.ext.asyncio import AsyncSession

from src.event_ticketing.domain.event_ticketing_aggregate import EventTicketingAggregate
from src.event_ticketing.domain.event_ticketing_command_repo import EventTicketingCommandRepo
from src.seat_reservation.infra.rocksdb_monitor import RocksDBMonitor
from src.shared.config.db_setting import get_async_session
from src.shared.config.di import Container
from src.shared.constant.path import BASE_DIR
from src.shared.logging.loguru_io import Logger
from src.shared_kernel.domain.kafka_config_service import KafkaConfigServiceInterface


class CreateEventUseCase:
    def __init__(
        self,
        session: AsyncSession,
        event_ticketing_command_repo: EventTicketingCommandRepo,
        kafka_service: KafkaConfigServiceInterface,
    ):
        self.session = session
        self.event_ticketing_command_repo = event_ticketing_command_repo
        self.kafka_service = kafka_service

    @classmethod
    @inject
    def depends(
        cls,
        session: AsyncSession = Depends(get_async_session),
        event_ticketing_command_repo: EventTicketingCommandRepo = Depends(
            Provide[Container.event_ticketing_command_repo]
        ),
        kafka_service: KafkaConfigServiceInterface = Depends(Provide[Container.kafka_service]),
    ):
        return cls(
            session=session,
            event_ticketing_command_repo=event_ticketing_command_repo,
            kafka_service=kafka_service,
        )

    @Logger.io
    async def create_event_and_tickets(
        self,
        *,
        name: str,
        description: str,
        seller_id: int,
        venue_name: str,
        seating_config: Dict,
        is_active: bool = True,
    ) -> EventTicketingAggregate:
        """
        å‰µå»ºæ´»å‹•å’Œç¥¨å‹™ - ä½¿ç”¨æ–°çš„èšåˆæ ¹

        Args:
            name: æ´»å‹•åç¨±
            description: æ´»å‹•æè¿°
            seller_id: è³£å®¶ ID
            venue_name: å ´åœ°åç¨±
            seating_config: åº§ä½é…ç½®
            is_active: æ˜¯å¦å•Ÿç”¨

        Returns:
            å‰µå»ºçš„ EventTicketingAggregate
        """

        # 1. å‰µå»º EventTicketingAggregate
        event_aggregate = EventTicketingAggregate.create_event_with_tickets(
            name=name,
            description=description,
            seller_id=seller_id,
            venue_name=venue_name,
            seating_config=seating_config,
            is_active=is_active,
        )

        # 2. ä¿å­˜ Event ä»¥ç²å¾— ID
        saved_aggregate = await self.event_ticketing_command_repo.create_event_aggregate(
            event_aggregate=event_aggregate
        )

        # 3. ç”Ÿæˆç¥¨å‹™ï¼ˆåŒæ™‚ç²å¾—æ‰¹é‡æ’å…¥æ ¼å¼ï¼‰
        ticket_tuples = saved_aggregate.generate_tickets()
        Logger.base.info(f'Prepared {len(ticket_tuples)} tickets for batch insert')

        # 4. ä½¿ç”¨é«˜æ•ˆèƒ½æ‰¹é‡å‰µå»ºæ–¹æ³•ä¿å­˜ tickets
        final_aggregate = (
            await self.event_ticketing_command_repo.create_event_aggregate_with_batch_tickets(
                event_aggregate=saved_aggregate,
                ticket_tuples=ticket_tuples,  # å‚³å…¥é å…ˆæº–å‚™å¥½çš„è³‡æ–™
            )
        )

        # 5. å•Ÿç”¨æ´»å‹• (å¾ DRAFT è½‰ç‚º AVAILABLE)
        final_aggregate.activate()

        # 6. æ›´æ–°æ´»å‹•ç‹€æ…‹åˆ°è³‡æ–™åº«
        final_aggregate = await self.event_ticketing_command_repo.update_event_aggregate(
            event_aggregate=final_aggregate
        )

        if not final_aggregate.event.id:
            raise Exception('Event ID is missing after creation')
        await self._setup_kafka_infrastructure(
            event_id=final_aggregate.event.id, seating_config=seating_config
        )

        # 6. åˆå§‹åŒ– RocksDB åº§ä½ - ç›´æ¥ä½¿ç”¨ SeatInitializationService
        await self._initialize_rocksdb_seats_direct(
            event_id=final_aggregate.event.id, tickets=final_aggregate.tickets
        )

        await self.session.commit()

        Logger.base.info(
            f'âœ… Created event {final_aggregate.event.id} with {len(final_aggregate.tickets)} tickets'
        )

        return final_aggregate

    @Logger.io
    async def _setup_kafka_infrastructure(self, *, event_id: int, seating_config: Dict) -> None:
        """è¨­ç½® Kafka åŸºç¤è¨­æ–½"""
        try:
            Logger.base.info(f'ğŸš€ Setting up Kafka infrastructure for event {event_id}')

            # æª¢æŸ¥ consumer æ˜¯å¦å¯ç”¨
            consumers_available = await self._check_consumer_availability()

            if not consumers_available:
                Logger.base.info('ğŸ”„ Consumers not available, attempting to start them...')
                startup_success = await self._auto_start_consumers(event_id)
                if startup_success:
                    Logger.base.info('âœ… Consumers started successfully')
                else:
                    Logger.base.warning('âš ï¸ Failed to auto-start consumers')

            # è¨­ç½®æ´»å‹•åŸºç¤è¨­æ–½
            infrastructure_success = await self.kafka_service.setup_event_infrastructure(
                event_id=event_id, seating_config=seating_config
            )

            if not infrastructure_success:
                Logger.base.warning(
                    f'âš ï¸ Infrastructure setup failed for event {event_id}, but continuing...'
                )

        except Exception as e:
            Logger.base.error(f'âŒ Failed to setup Kafka infrastructure: {e}')
            # ä¸æ‹‹å‡ºç•°å¸¸ï¼Œå› ç‚ºæ´»å‹•å·²ç¶“å‰µå»ºæˆåŠŸ

    @Logger.io
    async def _initialize_rocksdb_seats_direct(self, *, event_id: int, tickets: list) -> None:
        """ç›´æ¥åˆå§‹åŒ– RocksDB åº§ä½ - ä½¿ç”¨ç°¡å–®ç›´æ¥çš„æ–¹å¼"""
        try:
            Logger.base.info(
                f'ğŸ’º Directly initializing RocksDB seats for event {event_id} with {len(tickets)} tickets'
            )

            # ä½¿ç”¨ç¾æœ‰çš„ SeatInitializationService
            from src.seat_reservation.infra.seat_reservation_consumer import (
                SeatInitializationService,
            )

            seat_service = SeatInitializationService()
            initialized_count = await seat_service.initialize_seats_for_event(
                event_id=event_id, tickets=tickets
            )

            Logger.base.info(
                f'âœ… Directly initialized {initialized_count}/{len(tickets)} seats in RocksDB'
            )

            # é©—è­‰åˆå§‹åŒ–çµæœ
            await self._read_rocksdb_seats(event_id=event_id, sample_size=10)

        except Exception as e:
            Logger.base.error(f'âŒ Failed to directly initialize RocksDB seats: {e}')

    @Logger.io
    async def _read_rocksdb_seats(self, *, event_id: int, sample_size: int = 10) -> None:
        """è®€å– RocksDB åº§ä½ç‹€æ…‹é€²è¡Œé©—è­‰"""
        try:
            Logger.base.info(f'ğŸ” Reading RocksDB seats for event {event_id}')

            monitor = RocksDBMonitor()
            if not monitor.is_available():
                Logger.base.warning('âš ï¸ RocksDB monitor not available')
                return

            # ç²å–åº§ä½ç‹€æ…‹
            seats = monitor.get_all_seats(limit=sample_size)
            event_seats = [seat for seat in seats if seat.event_id == event_id]

            if event_seats:
                Logger.base.info(
                    f'ğŸ“Š Found {len(event_seats)} seats in RocksDB for event {event_id}'
                )
                for seat in event_seats[:5]:  # é¡¯ç¤ºå‰5å€‹åº§ä½
                    Logger.base.info(
                        f'   ğŸª‘ Seat {seat.seat_id}: {seat.status}, Price: {seat.price}'
                    )

                # ç²å–çµ±è¨ˆä¿¡æ¯
                stats = monitor.get_event_statistics(event_id)
                if stats:
                    Logger.base.info(f'ğŸ“ˆ Event {event_id} statistics:')
                    Logger.base.info(f'   Total seats: {stats.total_seats}')
                    Logger.base.info(f'   Available: {stats.available_seats}')
                    Logger.base.info(f'   Reserved: {stats.reserved_seats}')
                    Logger.base.info(f'   Sold: {stats.sold_seats}')
            else:
                Logger.base.warning(f'âš ï¸ No seats found in RocksDB for event {event_id}')

        except Exception as e:
            Logger.base.error(f'âŒ Failed to read RocksDB seats: {e}')

    @Logger.io
    async def _check_consumer_availability(self) -> bool:
        """æª¢æŸ¥å¿…è¦çš„ consumer æ˜¯å¦é‹è¡Œ"""
        try:
            # æ ¹æ“šæ—¥èªŒé¡¯ç¤ºçš„å¯¦éš› consumer group åç¨±æ›´æ–°
            required_groups = [
                'ticketing-system',  # å¾æ—¥èªŒçœ‹åˆ°çš„å¯¦éš› group åç¨±ä¹‹ä¸€
                'seat-reservation-service',  # å¾æ—¥èªŒçœ‹åˆ°çš„å¯¦éš› group åç¨±
            ]

            active_groups = await self.kafka_service.get_active_consumer_groups()
            Logger.base.info(f'ğŸ“‹ Active consumer groups: {active_groups}')

            missing_groups = []
            for group in required_groups:
                # æª¢æŸ¥æ˜¯å¦æœ‰åŒ…å«è©²é—œéµå­—çš„ groupï¼ˆå› ç‚ºå¯¦éš›åç¨±å¯èƒ½åŒ…å«éš¨æ©Ÿå¾Œç¶´ï¼‰
                group_found = any(group in active_group for active_group in active_groups)
                if not group_found:
                    missing_groups.append(group)
                    Logger.base.warning(
                        f"âš ï¸ Consumer group pattern '{group}' not found in active groups"
                    )

            if missing_groups:
                Logger.base.warning(f'âš ï¸ Missing consumer groups: {missing_groups}')
                return False

            Logger.base.info('âœ… All required consumers are active')
            return True

        except Exception as e:
            Logger.base.warning(f'âš ï¸ Failed to check consumer status: {e}')
            return False

    async def _auto_start_consumers(self, event_id: int) -> bool:
        """è‡ªå‹•å•Ÿå‹• consumers"""
        try:
            project_root = BASE_DIR

            consumers = [
                ('booking_mq_consumer', 'src.booking.infra.booking_mq_consumer'),
                (
                    'seat_reservation_consumer_1',
                    'src.seat_reservation.infra.seat_reservation_consumer',
                ),
                (
                    'seat_reservation_consumer_2',
                    'src.seat_reservation.infra.seat_reservation_consumer',
                ),
                (
                    'event_ticketing_mq_consumer',
                    'src.event_ticketing.infra.event_ticketing_mq_consumer',
                ),
            ]

            processes = []
            for name, module in consumers:
                try:
                    env = os.environ.copy()
                    env['EVENT_ID'] = str(event_id)
                    env['PYTHONPATH'] = str(project_root)

                    cmd = ['uv', 'run', 'python', '-m', module]

                    process = await asyncio.create_subprocess_exec(
                        *cmd,
                        cwd=project_root,
                        env=env,
                        stdout=asyncio.subprocess.PIPE,
                        stderr=asyncio.subprocess.PIPE,
                        start_new_session=True,
                    )

                    processes.append((name, process))
                    Logger.base.info(f'âœ… Started {name} (PID: {process.pid})')

                except Exception as e:
                    Logger.base.error(f'âŒ Failed to start {name}: {e}')
                    return False

            # ç­‰å¾… consumers åˆå§‹åŒ–
            await asyncio.sleep(3)

            # é©—è­‰ consumers æ˜¯å¦çœŸçš„å•Ÿå‹•äº†
            return await self._check_consumer_availability()

        except Exception as e:
            Logger.base.error(f'âŒ Auto-start consumers failed: {e}')
            return False
