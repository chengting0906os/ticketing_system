"""
Create Event Use Case - ä½¿ç”¨æ–°çš„ EventTicketingAggregate

é‡æ§‹å¾Œçš„æ´»å‹•å‰µå»ºæ¥­å‹™é‚è¼¯ï¼š
- ä½¿ç”¨ EventTicketingAggregate ä½œç‚ºèšåˆæ ¹
- æ•´åˆæ´»å‹•å’Œç¥¨å‹™å‰µå»ºé‚è¼¯
- è² è²¬ Kafka åŸºç¤è¨­æ–½åˆå§‹åŒ–
- è™•ç† Kvrocks åº§ä½åˆå§‹åŒ–
"""

import asyncio
import os
from typing import Dict

from dependency_injector.wiring import Provide, inject
from fastapi import Depends
from quixstreams import Application
from sqlalchemy.ext.asyncio import AsyncSession

from src.event_ticketing.domain.event_ticketing_aggregate import EventTicketingAggregate
from src.event_ticketing.domain.event_ticketing_command_repo import EventTicketingCommandRepo
from src.platform.config.core_setting import settings
from src.platform.config.db_setting import get_async_session
from src.platform.config.di import Container
from src.platform.constant.path import BASE_DIR
from src.platform.logging.loguru_io import Logger
from src.platform.message_queue.kafka_constant_builder import (
    KafkaConsumerGroupBuilder,
    KafkaTopicBuilder,
    PartitionKeyBuilder,
)
from src.shared_kernel.domain.event_status import EventStatus
from src.shared_kernel.domain.kafka_config_service import KafkaConfigServiceInterface


class CreateEventUseCase:
    def __init__(
        self,
        session: AsyncSession,
        event_ticketing_command_repo: EventTicketingCommandRepo,
        kafka_service: KafkaConfigServiceInterface,
    ):
        self.session = session
        self.event_ticketing_command_repo = event_ticketing_command_repo
        self.kafka_service = kafka_service

    @classmethod
    @inject
    def depends(
        cls,
        session: AsyncSession = Depends(get_async_session),
        event_ticketing_command_repo: EventTicketingCommandRepo = Depends(
            Provide[Container.event_ticketing_command_repo]
        ),
        kafka_service: KafkaConfigServiceInterface = Depends(Provide[Container.kafka_service]),
    ):
        return cls(
            session=session,
            event_ticketing_command_repo=event_ticketing_command_repo,
            kafka_service=kafka_service,
        )

    @Logger.io
    async def create_event_and_tickets(
        self,
        *,
        name: str,
        description: str,
        seller_id: int,
        venue_name: str,
        seating_config: Dict,
        is_active: bool = True,
    ) -> EventTicketingAggregate:
        """
        å‰µå»ºæ´»å‹•å’Œç¥¨å‹™ - ä½¿ç”¨æ–°çš„èšåˆæ ¹

        Args:
            name: æ´»å‹•åç¨±
            description: æ´»å‹•æè¿°
            seller_id: è³£å®¶ ID
            venue_name: å ´åœ°åç¨±
            seating_config: åº§ä½é…ç½®
            is_active: æ˜¯å¦å•Ÿç”¨

        Returns:
            å‰µå»ºçš„ EventTicketingAggregate
        """

        # 1. å‰µå»º EventTicketingAggregate
        event_aggregate = EventTicketingAggregate.create_event_with_tickets(
            name=name,
            description=description,
            seller_id=seller_id,
            venue_name=venue_name,
            seating_config=seating_config,
            is_active=is_active,
        )

        # 2. ä¿å­˜ Event ä»¥ç²å¾— ID
        saved_aggregate = await self.event_ticketing_command_repo.create_event_aggregate(
            event_aggregate=event_aggregate
        )

        # 3. ç”Ÿæˆç¥¨å‹™ï¼ˆåŒæ™‚ç²å¾—æ‰¹é‡æ’å…¥æ ¼å¼ï¼‰
        ticket_tuples = saved_aggregate.generate_tickets()
        Logger.base.info(f'Prepared {len(ticket_tuples)} tickets for batch insert')

        # 4. ä½¿ç”¨é«˜æ•ˆèƒ½æ‰¹é‡å‰µå»ºæ–¹æ³•ä¿å­˜ tickets
        final_aggregate = (
            await self.event_ticketing_command_repo.create_event_aggregate_with_batch_tickets(
                event_aggregate=saved_aggregate,
                ticket_tuples=ticket_tuples,  # å‚³å…¥é å…ˆæº–å‚™å¥½çš„è³‡æ–™
            )
        )

        # 5. å•Ÿç”¨æ´»å‹• (DRAFT â†’ AVAILABLE)
        final_aggregate.event.status = EventStatus.AVAILABLE

        if not final_aggregate.event.id:
            raise Exception('Event ID is missing after creation')
        await self._setup_kafka_infrastructure(
            event_id=final_aggregate.event.id, seating_config=seating_config
        )

        # 6. å•Ÿå‹• seat_reservation consumer ä¸¦åˆå§‹åŒ–åº§ä½
        await self._start_seat_reservation_consumer_and_initialize_seats(
            event_id=final_aggregate.event.id, ticket_tuples=ticket_tuples
        )

        await self.session.commit()

        Logger.base.info(
            f'âœ… Created event {final_aggregate.event.id} with {len(final_aggregate.tickets)} tickets'
        )

        return final_aggregate

    @Logger.io
    async def _setup_kafka_infrastructure(self, *, event_id: int, seating_config: Dict) -> None:
        """è¨­ç½® Kafka åŸºç¤è¨­æ–½"""
        try:
            Logger.base.info(f'ğŸš€ Setting up Kafka infrastructure for event {event_id}')

            # æª¢æŸ¥ consumer æ˜¯å¦å¯ç”¨
            consumers_available = await self._check_consumer_availability(event_id=event_id)

            if not consumers_available:
                Logger.base.info('ğŸ”„ Consumers not available, attempting to start them...')
                startup_success = await self._auto_start_consumers(event_id)
                if startup_success:
                    Logger.base.info('âœ… Consumers started successfully')
                else:
                    Logger.base.warning('âš ï¸ Failed to auto-start consumers')

            # è¨­ç½®æ´»å‹•åŸºç¤è¨­æ–½
            infrastructure_success = await self.kafka_service.setup_event_infrastructure(
                event_id=event_id, seating_config=seating_config
            )

            if not infrastructure_success:
                Logger.base.warning(
                    f'âš ï¸ Infrastructure setup failed for event {event_id}, but continuing...'
                )

        except Exception as e:
            Logger.base.error(f'âŒ Failed to setup Kafka infrastructure: {e}')
            # ä¸æ‹‹å‡ºç•°å¸¸ï¼Œå› ç‚ºæ´»å‹•å·²ç¶“å‰µå»ºæˆåŠŸ

    @Logger.io
    async def _start_seat_reservation_consumer_and_initialize_seats(
        self, *, event_id: int, ticket_tuples: list
    ) -> None:
        """ç¢ºä¿ seat_reservation consumer é‹è¡Œä¸¦åˆå§‹åŒ–åº§ä½"""
        try:
            # 1. æª¢æŸ¥ consumers æ˜¯å¦å·²ç¶“å•Ÿå‹•
            consumers_available = await self._check_consumer_availability(event_id=event_id)

            if not consumers_available:
                Logger.base.info(
                    f'ğŸš€ Consumers not running, starting seat_reservation consumer for event {event_id}'
                )
                await self._start_seat_reservation_consumer(event_id=event_id)
                # ç­‰å¾… consumer æº–å‚™å°±ç·’
                await asyncio.sleep(3)
            else:
                Logger.base.info(f'âœ… Consumers already running for event {event_id}')

            # 2. ç™¼é€åº§ä½åˆå§‹åŒ–äº‹ä»¶
            await self._send_seat_initialization_events(
                event_id=event_id, ticket_tuples=ticket_tuples
            )

            # 3. ç­‰å¾…è™•ç†å®Œæˆ
            await asyncio.sleep(8)

        except Exception as e:
            Logger.base.error(f'âŒ Failed to initialize seats: {e}')

    @Logger.io
    async def _start_seat_reservation_consumer(self, *, event_id: int) -> None:
        """å•Ÿå‹•ç‰¹å®šäº‹ä»¶çš„ seat_reservation consumer"""
        try:
            project_root = BASE_DIR
            env = os.environ.copy()
            env['EVENT_ID'] = str(event_id)
            env['PYTHONPATH'] = str(project_root)
            env['CONSUMER_GROUP_ID'] = KafkaConsumerGroupBuilder.seat_reservation_service(
                event_id=event_id
            )
            env['CONSUMER_INSTANCE_ID'] = '1'

            cmd = [
                'uv',
                'run',
                'python',
                '-m',
                'src.seat_reservation.driving.seat_reservation_mq_consumer',
            ]

            process = await asyncio.create_subprocess_exec(
                *cmd,
                cwd=project_root,
                env=env,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                start_new_session=True,
            )

            Logger.base.info(
                f'âœ… Started seat_reservation_mq_consumer (PID: {process.pid}) for event {event_id}'
            )

        except Exception as e:
            Logger.base.error(f'âŒ Failed to start seat_reservation consumer: {e}')
            raise

    @Logger.io
    async def _send_seat_initialization_events(self, *, event_id: int, ticket_tuples: list) -> None:
        """ç™¼é€åº§ä½åˆå§‹åŒ–äº‹ä»¶åˆ° Kafka"""
        try:
            Logger.base.info(
                f'ğŸ’º Sending seat initialization events for event {event_id} with {len(ticket_tuples)} tickets'
            )

            # 1. å…ˆå¯«å…¥ subsection_total metadata åˆ° Kvrocks
            from src.platform.redis.redis_client import kvrocks_client_sync

            subsection_counts = {}
            for ticket_tuple in ticket_tuples:
                _, section, subsection, _, _, _, _ = ticket_tuple
                section_id = f'{section}-{subsection}'
                subsection_counts[section_id] = subsection_counts.get(section_id, 0) + 1

            client = kvrocks_client_sync.connect()
            for section_id, count in subsection_counts.items():
                key = f'subsection_total:{event_id}:{section_id}'
                client.set(key, count)
                Logger.base.info(f'ğŸ“Š Set {key} = {count}')

            # 2. ç™¼é€åº§ä½åˆå§‹åŒ–äº‹ä»¶åˆ° Kafka
            app = Application(
                broker_address=settings.KAFKA_BOOTSTRAP_SERVERS,
                producer_extra_config={
                    'enable.idempotence': True,
                    'acks': 'all',
                    'retries': 3,
                },
            )

            topic_name = KafkaTopicBuilder.seat_initialization_command_in_kvrocks(event_id=event_id)
            Logger.base.info(f'ğŸ“¡ Using seat initialization topic: {topic_name}')

            seat_init_topic = app.topic(
                name=topic_name,
                key_serializer='str',
                value_serializer='json',
            )

            initialized_count = 0

            with app.get_producer() as producer:
                for ticket_tuple in ticket_tuples:
                    try:
                        # ticket_tuple: (event_id, section, subsection, row, seat, price, status)
                        _, section, subsection, row, seat, price, _ = ticket_tuple
                        seat_id = f'{section}-{subsection}-{row}-{seat}'

                        # å‰µå»ºåº§ä½åˆå§‹åŒ–äº‹ä»¶
                        init_message = {
                            'action': 'INITIALIZE',
                            'seat_id': seat_id,
                            'event_id': event_id,
                            'price': price,
                            'section': section,
                            'subsection': subsection,
                            'row': row,
                            'seat': seat,
                        }

                        # ä½¿ç”¨ section-based partition keyï¼ŒæŒ‰å­—æ¯é †åºåˆ†é…ï¼šAâ†’0, Bâ†’1, Câ†’2...
                        # é€™æ¨£å¯ä»¥å°‡ä¸åŒ section çš„è² è¼‰åˆ†æ•£åˆ°ä¸åŒçš„ consumer instances
                        partition_number = ord(section[0]) - ord('A')
                        partition_key = PartitionKeyBuilder.section_based(
                            event_id=event_id, section=section, partition_number=partition_number
                        )

                        # ç™¼é€åˆ° Kafka
                        message = seat_init_topic.serialize(key=partition_key, value=init_message)
                        producer.produce(
                            topic=seat_init_topic.name,
                            value=message.value,
                            key=message.key,
                        )

                        initialized_count += 1

                    except Exception as e:
                        try:
                            # ticket_tuple: (event_id, section, subsection, row, seat, price, status)
                            if len(ticket_tuple) >= 5:
                                _, section_name, subsection_num, row_num, seat_num = ticket_tuple[
                                    :5
                                ]
                                seat_identifier = (
                                    f'{section_name}-{subsection_num}-{row_num}-{seat_num}'
                                )
                            else:
                                seat_identifier = 'invalid_tuple'
                        except (ValueError, IndexError):
                            seat_identifier = 'unknown'
                        Logger.base.warning(
                            f'âš ï¸ Failed to send initialization for seat {seat_identifier}: {e}'
                        )
                        continue

                # ç¢ºä¿æ‰€æœ‰äº‹ä»¶éƒ½ç™¼é€å®Œæˆ
                producer.flush(timeout=10.0)

            Logger.base.info(
                f'âœ… Sent {initialized_count}/{len(ticket_tuples)} seat initialization events to topic: {topic_name}'
            )

        except Exception as e:
            Logger.base.error(f'âŒ Failed to send seat initialization events: {e}')

    @Logger.io
    async def _check_consumer_availability(
        self, *, event_id: int, max_retries: int = 3, retry_delay: float = 2.0
    ) -> bool:
        """æª¢æŸ¥å¿…è¦çš„ consumer æ˜¯å¦é‹è¡Œï¼ŒåŒ…å«é‡è©¦æ©Ÿåˆ¶"""
        try:
            # 1-1-2 é…ç½®çš„ consumer groups
            required_groups = KafkaConsumerGroupBuilder.get_all_consumer_groups(event_id=event_id)
            missing_groups = []

            for attempt in range(max_retries):
                active_groups = await self.kafka_service.get_active_consumer_groups()
                Logger.base.info(
                    f'ğŸ“‹ Active consumer groups (attempt {attempt + 1}): {active_groups}'
                )

                missing_groups = []
                for group in required_groups:
                    # æª¢æŸ¥æ˜¯å¦æœ‰åŒ…å«è©²é—œéµå­—çš„ groupï¼ˆå› ç‚ºå¯¦éš›åç¨±å¯èƒ½åŒ…å«éš¨æ©Ÿå¾Œç¶´ï¼‰
                    group_found = any(group in active_group for active_group in active_groups)
                    if not group_found:
                        missing_groups.append(group)
                        Logger.base.warning(
                            f"âš ï¸ Consumer group pattern '{group}' not found in active groups"
                        )

                if not missing_groups:
                    Logger.base.info('âœ… All required consumers are active')
                    return True

                if attempt < max_retries - 1:  # Don't sleep on the last attempt
                    Logger.base.info(
                        f'ğŸ”„ Retrying consumer verification in {retry_delay}s... (attempt {attempt + 1}/{max_retries})'
                    )
                    await asyncio.sleep(retry_delay)

            Logger.base.warning(
                f'âš ï¸ Missing consumer groups after {max_retries} attempts: {missing_groups}'
            )
            return False

        except Exception as e:
            Logger.base.warning(f'âš ï¸ Failed to check consumer status: {e}')
            return False

    async def _auto_start_consumers(self, event_id: int) -> bool:
        """
        è‡ªå‹•å•Ÿå‹• consumers - 1-2-1 é…ç½®

        æ¶æ§‹é…ç½®ï¼š
        - booking: 1 consumer (è¼•é‡ç´šè¨‚å–®è™•ç†)
        - seat_reservation: 2 consumers (åº§ä½é¸æ“‡ç®—æ³• + Kvrocks è®€å¯«)
        - event_ticketing: 1 consumer (ç‹€æ…‹ç®¡ç†)
        """
        try:
            project_root = BASE_DIR

            # 1-2-1 Consumer é…ç½®
            consumers = [
                # Booking Service - 1 consumer
                {
                    'name': 'booking_mq_consumer',
                    'module': 'src.booking.driving.booking_mq_consumer',
                    'group_id': KafkaConsumerGroupBuilder.booking_service(event_id=event_id),
                    'instance_id': 1,
                },
                # Seat Reservation - 2 consumers (é«˜è² è¼‰åº§ä½é¸æ“‡ + Kvrocks æ“ä½œ)
                {
                    'name': 'seat_reservation_mq_consumer_1',
                    'module': 'src.seat_reservation.driving.seat_reservation_mq_consumer',
                    'group_id': KafkaConsumerGroupBuilder.seat_reservation_service(
                        event_id=event_id
                    ),
                    'instance_id': 1,
                },
                # {
                #     'name': 'seat_reservation_mq_consumer_2',
                #     'module': 'src.seat_reservation.driving.seat_reservation_mq_consumer',
                #     'group_id': KafkaConsumerGroupBuilder.seat_reservation_service(
                #         event_id=event_id
                #     ),
                #     'instance_id': 2,
                # },
                # Event Ticketing - 1 consumer
                {
                    'name': 'event_ticketing_mq_consumer',
                    'module': 'src.event_ticketing.driven.event_ticketing_mq_consumer',
                    'group_id': KafkaConsumerGroupBuilder.event_ticketing_service(
                        event_id=event_id
                    ),
                    'instance_id': 1,
                },
            ]

            processes = []
            for consumer_config in consumers:
                try:
                    env = os.environ.copy()
                    env['EVENT_ID'] = str(event_id)
                    env['PYTHONPATH'] = str(project_root)
                    env['CONSUMER_GROUP_ID'] = consumer_config['group_id']
                    env['CONSUMER_INSTANCE_ID'] = str(consumer_config['instance_id'])

                    cmd = ['uv', 'run', 'python', '-m', consumer_config['module']]

                    process = await asyncio.create_subprocess_exec(
                        *cmd,
                        cwd=project_root,
                        env=env,
                        stdout=asyncio.subprocess.PIPE,
                        stderr=asyncio.subprocess.PIPE,
                        start_new_session=True,
                    )

                    processes.append((consumer_config['name'], process))
                    Logger.base.info(
                        f'âœ… Started {consumer_config["name"]} '
                        f'(PID: {process.pid}, Group: {consumer_config["group_id"]})'
                    )

                except Exception as e:
                    Logger.base.error(f'âŒ Failed to start {consumer_config["name"]}: {e}')
                    return False

            # ç­‰å¾… consumers åˆå§‹åŒ–
            await asyncio.sleep(5)  # å¢åŠ ç­‰å¾…æ™‚é–“ç¢ºä¿æ‰€æœ‰ consumer å•Ÿå‹•

            Logger.base.info(f'ğŸ“Š [1-2-1 CONFIG] Total consumers started: {len(processes)}')
            Logger.base.info('ğŸ”„ [1-2-1 CONFIG] booking:1, seat_reservation:2, event_ticketing:1')

            # é©—è­‰ consumers æ˜¯å¦çœŸçš„å•Ÿå‹•äº†
            return await self._check_consumer_availability(event_id=event_id)

        except Exception as e:
            Logger.base.error(f'âŒ Auto-start consumers failed: {e}')
            return False
