"""
Domain Event Publisher
é ˜åŸŸäº‹ä»¶ç™¼å¸ƒå™¨

ç°¡åŒ–ç‰ˆäº‹ä»¶ç™¼å¸ƒæ¥å£ - ç›´æ¥ä½¿ç”¨ Quix Streams
"""

from typing import Literal

from quixstreams import Application

from src.platform.config.core_setting import settings
from src.platform.logging.loguru_io import Logger
from src.shared_kernel.domain.domain_event.mq_domain_event import MqDomainEvent


# å…¨åŸŸ Quix Application å¯¦ä¾‹
_quix_app: Application | None = None


def _get_quix_app() -> Application:
    """å–å¾—å…¨åŸŸ Quix Application å¯¦ä¾‹"""
    global _quix_app
    if _quix_app is None:
        _quix_app = Application(
            broker_address=settings.KAFKA_BOOTSTRAP_SERVERS,
            producer_extra_config={
                'enable.idempotence': True,
                'acks': 'all',
                'retries': 3,
                'compression.type': 'snappy',
            },
        )
    return _quix_app


@Logger.io
async def publish_domain_event(
    event: MqDomainEvent,
    topic: str,
    partition_key: str,
) -> Literal[True]:
    """
    ç™¼å¸ƒé ˜åŸŸäº‹ä»¶åˆ° Kafka

    Args:
        event: é ˜åŸŸäº‹ä»¶å°è±¡
        topic: Kafka topic åç¨±
        partition_key: åˆ†å€éµï¼ˆç¢ºä¿ç›¸åŒå¯¦é«”çš„äº‹ä»¶é †åºè™•ç†ï¼‰

    Returns:
        Trueï¼ˆæ°¸é æˆåŠŸï¼Œå¤±æ•—æœƒæ‹‹å‡ºç•°å¸¸ï¼‰

    ç¯„ä¾‹:
        await publish_domain_event(
            event=BookingCreated(booking_id=123, ...),
            topic=KafkaTopicBuilder.ticket_reserving_request(...),
            partition_key="booking-123"
        )
    """
    app = _get_quix_app()

    # å‰µå»º topicï¼ˆQuix æœƒè‡ªå‹•è™•ç†é‡è¤‡å‰µå»ºï¼‰
    kafka_topic = app.topic(
        name=topic,
        key_serializer='str',
        value_serializer='json',
    )

    # æº–å‚™äº‹ä»¶æ•¸æ“š
    event_data = {
        'event_type': event.__class__.__name__,
        'aggregate_id': str(event.aggregate_id),
        'occurred_at': int(event.occurred_at.timestamp()),
        **event.__dict__,
    }

    # ç§»é™¤å·²åŒ…å«çš„æ¬„ä½
    event_data.pop('aggregate_id', None)
    event_data.pop('occurred_at', None)

    # ç™¼å¸ƒäº‹ä»¶
    with app.get_producer() as producer:
        message = kafka_topic.serialize(
            key=partition_key,
            value=event_data,
        )

        producer.produce(
            topic=kafka_topic.name,
            key=message.key,
            value=message.value,
        )

        producer.flush(timeout=5.0)

    Logger.base.info(f'ğŸ“¤ Published {event.__class__.__name__} to {topic} (key: {partition_key})')

    return True
