"""
Kafka Configuration Service
ç‚ºæ´»å‹•é…ç½® Kafka topics å’Œ partition strategy
"""

import asyncio
import os
from typing import Dict

from src.platform.logging.loguru_io import Logger
from src.service.ticketing.app.interface.i_kafka_config_service import IKafkaConfigService

from .kafka_constant_builder import KafkaTopicBuilder
from .section_based_partition_strategy import SectionBasedPartitionStrategy


class KafkaConfigService(IKafkaConfigService):
    """
    Kafka é…ç½®æœå‹™

    è² è²¬ç‚ºæ–°æ´»å‹•é…ç½®:
    1. Event-specific topics
    2. Section-based partition strategy

    Note: Consumer management is handled by Docker Compose
    """

    def __init__(self, total_partitions: int = 100):
        self.total_partitions = total_partitions
        self.partition_strategy = SectionBasedPartitionStrategy(total_partitions)

    @Logger.io
    async def setup_event_infrastructure(self, *, event_id: int, seating_config: Dict) -> bool:
        """
        Setup Kafka infrastructure for new event

        Creates topics and analyzes partition distribution
        Note: Consumer management is handled by Docker Compose

        Returns:
            bool: Setup success status
        """
        try:
            Logger.base.info(f'ðŸš€ [KAFKA] Setting up infrastructure for EVENT_ID={event_id}')

            await self._create_event_topics(event_id)
            self._analyze_partition_distribution(event_id, seating_config)

            Logger.base.info(f'âœ… [KAFKA] Infrastructure setup completed for EVENT_ID={event_id}')
            return True

        except Exception as e:
            Logger.base.error(
                f'âŒ [KAFKA] Failed to setup infrastructure for EVENT_ID={event_id}: {e}'
            )
            return False

    async def _create_event_topics(self, event_id: int) -> None:
        """å‰µå»º event-specific topics"""
        Logger.base.info(
            f'ðŸŽ¯ [KAFKA_CONFIG] Creating event-specific topics for EVENT_ID={event_id}'
        )

        topics = KafkaTopicBuilder.get_all_topics(event_id=event_id)

        # ä¸¦è¡Œå‰µå»ºæ‰€æœ‰ topics ä»¥æé«˜æ•ˆçŽ‡
        tasks = [self._create_single_topic(topic) for topic in topics]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # çµ±è¨ˆçµæžœ
        success_count = sum(1 for result in results if result is True)
        Logger.base.info(
            f'ðŸ“Š [KAFKA_CONFIG] Created {success_count}/{len(topics)} topics successfully'
        )

    async def _create_single_topic(self, topic: str) -> bool:
        """å‰µå»ºå–®å€‹ topic"""
        try:
            # Use full path to docker or search PATH explicitly
            docker_cmd = self._find_docker_executable()

            cmd = [
                docker_cmd,
                'exec',
                'kafka1',
                'kafka-topics',
                '--bootstrap-server',
                'kafka1:29092',
                '--create',
                '--if-not-exists',
                '--topic',
                topic,
                '--partitions',
                str(self.total_partitions),
                '--replication-factor',
                '3',
            ]

            # ä½¿ç”¨ asyncio åŸ·è¡Œ subprocess
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                env=os.environ.copy(),  # Explicitly pass environment
            )

            _, stderr = await asyncio.wait_for(process.communicate(), timeout=30)

            if process.returncode == 0:
                Logger.base.info(f'âœ… [KAFKA_CONFIG] Created topic: {topic}')
                return True
            else:
                Logger.base.warning(
                    f'âš ï¸ [KAFKA_CONFIG] Failed to create topic {topic}: {stderr.decode()}'
                )
                return False

        except asyncio.TimeoutError:
            Logger.base.error(f'âŒ [KAFKA_CONFIG] Timeout creating topic: {topic}')
            return False
        except Exception as e:
            Logger.base.error(f'âŒ [KAFKA_CONFIG] Error creating topic {topic}: {e}')
            return False

    def _analyze_partition_distribution(self, event_id: int, seating_config: Dict) -> None:
        """åˆ†æžä¸¦è¨˜éŒ„ partition åˆ†ä½ˆç­–ç•¥"""
        Logger.base.info(
            f'ðŸ“Š [KAFKA_CONFIG] Analyzing partition distribution for EVENT_ID={event_id}'
        )

        # ç²å–å€åŸŸåˆ° partition çš„æ˜ å°„
        sections = seating_config.get('sections', [])
        mapping = self.partition_strategy.get_section_partition_mapping(sections, event_id)

        # è¨ˆç®—è² è¼‰åˆ†ä½ˆ
        loads = self.partition_strategy.calculate_expected_load(seating_config, event_id)

        # è¨˜éŒ„æ˜ å°„é—œä¿‚
        Logger.base.info('ðŸ—ºï¸ [KAFKA_CONFIG] Subsection-to-Partition Mapping:')
        for subsection, partition in mapping.items():
            Logger.base.info(f'   {subsection} â†’ Partition {partition}')

        # è¨˜éŒ„è² è¼‰åˆ†ä½ˆ
        Logger.base.info('âš–ï¸ [KAFKA_CONFIG] Partition Load Distribution:')
        total_seats = 0
        for partition_id in sorted(loads.keys()):
            load_info = loads[partition_id]
            subsections_str = ', '.join(load_info['subsections'])
            seat_count = load_info['estimated_seats']
            total_seats += seat_count

            Logger.base.info(
                f'   Partition {partition_id}: {seat_count:,} seats ({subsections_str})'
            )

        Logger.base.info(f'ðŸ“ˆ [KAFKA] Total seats: {total_seats:,}')

    def _find_docker_executable(self) -> str:
        """Find docker executable path"""
        import shutil

        docker_path = shutil.which('docker')
        if docker_path:
            return docker_path

        # Fallback to common locations
        common_paths = ['/usr/local/bin/docker', '/usr/bin/docker']
        for path in common_paths:
            if os.path.exists(path):
                return path

        return 'docker'
