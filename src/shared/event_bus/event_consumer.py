"""
çµ±ä¸€çš„ Kafka äº‹ä»¶æ¶ˆè²»è€… (Unified Event Consumer)

ã€æœ€å°å¯è¡ŒåŸå‰‡ MVPã€‘
- é€™æ˜¯ä»€éº¼ï¼šå¾Kafkaæ¥æ”¶äº‹ä»¶ä¸¦è·¯ç”±åˆ°å°æ‡‰è™•ç†å™¨çš„çµ±ä¸€æ¥å£
- ç‚ºä»€éº¼éœ€è¦ï¼šé¿å…é‡è¤‡çš„æ¶ˆè²»è€…ä»£ç¢¼ï¼Œçµ±ä¸€äº‹ä»¶è™•ç†é‚è¼¯
- æ ¸å¿ƒæ¦‚å¿µï¼šæ¶ˆè²»è€…æ¨¡å¼ + äº‹ä»¶è·¯ç”± + è™•ç†å™¨è¨»å†Š
- ä½¿ç”¨å ´æ™¯ï¼šbookingæœå‹™æ¥æ”¶ticketingæœå‹™çš„å›æ‡‰äº‹ä»¶
"""

from abc import ABC, abstractmethod
import base64
from typing import Any, Dict, List, Optional

import anyio
from google.protobuf.json_format import MessageToDict
import orjson
from quixstreams import Application
import sniffio

from src.event_ticketing.port.event_ticketing_mq_gateway import (
    BookingCreatedCommand,
    EventTicketingMqGateway,
)
from src.shared.config.core_setting import settings
from src.shared.logging.loguru_io import Logger


class EventHandler(ABC):
    """
    äº‹ä»¶è™•ç†å™¨çš„æŠ½è±¡åŸºé¡

    ã€MVPåŸå‰‡ã€‘æ‰€æœ‰äº‹ä»¶è™•ç†å™¨å¿…é ˆå¯¦ç¾çš„å…©å€‹æ ¸å¿ƒæ–¹æ³•ï¼š
    1. can_handle: åˆ¤æ–·æ˜¯å¦èƒ½è™•ç†æŸç¨®äº‹ä»¶é¡å‹
    2. handle: å¯¦éš›è™•ç†äº‹ä»¶çš„æ¥­å‹™é‚è¼¯
    """

    @abstractmethod
    async def can_handle(self, event_type: str) -> bool:
        """
        æª¢æŸ¥æ˜¯å¦å¯ä»¥è™•ç†æŒ‡å®šçš„äº‹ä»¶é¡å‹

        ã€MVPè·¯ç”±åŸå‰‡ã€‘
        è¿”å›Trueè¡¨ç¤ºé€™å€‹è™•ç†å™¨å¯ä»¥è™•ç†è©²äº‹ä»¶é¡å‹
        ä¾‹å¦‚ï¼šBookingEventHandler.can_handle("TicketsReserved") -> True
        """
        pass

    @abstractmethod
    async def handle(self, event_data: Dict[str, Any]) -> bool:
        """
        è™•ç†äº‹ä»¶çš„å…·é«”æ¥­å‹™é‚è¼¯

        ã€MVPè™•ç†åŸå‰‡ã€‘
        æ¥æ”¶ååºåˆ—åŒ–å¾Œçš„äº‹ä»¶æ•¸æ“šï¼ŒåŸ·è¡Œç›¸æ‡‰çš„æ¥­å‹™æ“ä½œ
        è¿”å›Trueè¡¨ç¤ºè™•ç†æˆåŠŸï¼ŒFalseè¡¨ç¤ºè™•ç†å¤±æ•—
        ä¾‹å¦‚ï¼šæ›´æ–°bookingç‹€æ…‹ã€ç™¼é€é€šçŸ¥ç­‰
        """
        pass


class UnifiedEventConsumer:
    """
    çµ±ä¸€çš„äº‹ä»¶æ¶ˆè²»è€… (Quix Streams ç‰ˆæœ¬)

    ã€Quix Streams å„ªå‹¢ã€‘
    1. ç°¡åŒ–çš„ APIï¼Œæ¸›å°‘æ¨£æ¿ä»£ç¢¼
    2. å…§å»ºç•°æ­¥æ”¯æŒå’ŒéŒ¯èª¤è™•ç†
    3. è‡ªå‹• offset ç®¡ç†å’Œé‡è©¦æ©Ÿåˆ¶
    4. æ›´å¥½çš„æ€§èƒ½å’Œè³‡æºç®¡ç†
    """

    @Logger.io
    def __init__(
        self,
        topics: List[str],
        consumer_group_id: str = 'ticketing-system',
        consumer_tag: str = '[CONSUMER]',
    ):
        """
        åˆå§‹åŒ–çµ±ä¸€äº‹ä»¶æ¶ˆè²»è€…

        Args:
            topics: è¦è¨‚é–±çš„Kafkaä¸»é¡Œåˆ—è¡¨
            consumer_group_id: Kafkaæ¶ˆè²»è€…çµ„ID
            consumer_tag: æ¶ˆè²»è€…æ¨™è­˜ï¼Œç”¨æ–¼æ—¥èªŒè¿½è¹¤
        """

        self.topics = topics
        self.consumer_group_id = consumer_group_id
        self.consumer_tag = consumer_tag
        self.running = False
        self.handlers: List[EventHandler] = []

        # åˆå§‹åŒ– Quix Applicationï¼ˆä½¿ç”¨æ–°çš„ Consumer Group ID ä»¥é‡æ–°è™•ç†æ¶ˆæ¯ï¼‰
        import uuid

        new_consumer_group = f'{consumer_group_id}-{uuid.uuid4().hex[:8]}'
        Logger.base.info(
            f'\033[93mğŸ”„ [CONSUMER] ä½¿ç”¨æ–°çš„ Consumer Group: {new_consumer_group}\033[0m'
        )

        self.app = Application(
            broker_address=settings.KAFKA_BOOTSTRAP_SERVERS,
            consumer_group=new_consumer_group,
            auto_offset_reset='latest',  # å¾æœ€æ–°æ¶ˆæ¯é–‹å§‹ï¼Œè·³éæœ‰å•é¡Œçš„èˆŠæ¶ˆæ¯
            processing_guarantee='exactly-once',  # å•Ÿç”¨ exactly-once èªç¾©
            consumer_extra_config={
                'enable.auto.commit': True,
                'auto.commit.interval.ms': 1000,
                'session.timeout.ms': 30000,
                'heartbeat.interval.ms': 10000,
            },
        )

    @Logger.io
    def register_handler(self, handler: EventHandler) -> None:
        """è¨»å†Šäº‹ä»¶è™•ç†å™¨"""
        self.handlers.append(handler)

    @Logger.io
    async def start(self):
        """
        å•Ÿå‹• Quix Streams æ¶ˆè²»è€… (ç´” Protobuf ç‰ˆæœ¬)

        ã€Protobuf æµç¨‹ã€‘
        1. å‰µå»º Protobuf topics å’Œ streaming dataframe
        2. è¨­ç½®è‡ªå‹•ååºåˆ—åŒ–æµæ°´ç·š
        3. é‹è¡Œ streaming application
        """
        try:
            from quixstreams.models.serializers.protobuf import ProtobufDeserializer

            import src.shared.event_bus.proto.domain_event_pb2 as domain_event_pb2

            # Protobuf class with type stub support
            DomainEventProtoBufClass = domain_event_pb2.DomainEvent

            # ç‚ºæ¯å€‹ topic å‰µå»º Protobuf topic å°è±¡
            quix_topics = []
            for topic_name in self.topics:
                topic = self.app.topic(
                    name=topic_name,
                    value_deserializer=ProtobufDeserializer(
                        msg_type=DomainEventProtoBufClass,
                        to_dict=False,  # ä¿æŒ Protobuf å°è±¡æ ¼å¼ # è«‹å‹¿æ›´å‹•
                    ),
                    key_deserializer='str',
                )
                quix_topics.append(topic)

            # ç‚ºæ¯å€‹ topic å‰µå»º streaming dataframe
            Logger.base.info(f'ğŸ”— [CONSUMER] è¨­ç½® topic ç›£è½: {[t.name for t in quix_topics]}')

            for i, topic in enumerate(quix_topics):
                Logger.base.info(f'ğŸ”— [CONSUMER] è™•ç† topic {i}: {topic.name}')
                topic_sdf = self.app.dataframe(topic=topic)
                topic_sdf = topic_sdf.apply(self._deserialize_message)  # è½‰æ›ç‚ºå­—å…¸
                topic_sdf = topic_sdf.apply(self._log_before_filter)  # è¨˜éŒ„éæ¿¾å‰çš„æ•¸æ“š
                topic_sdf = topic_sdf.filter(
                    lambda x: x.get('event_type') is not None
                )  # éæ¿¾æœ‰æ•ˆäº‹ä»¶
                topic_sdf = topic_sdf.apply(self._process_event_with_handlers_sync)

            Logger.base.info(f'âœ… [CONSUMER] ç›£è½æ‰€æœ‰ topics: {self.topics}')

            self.running = True
            Logger.base.info(
                f'{self.consumer_tag} Quix Streams Consumer started for topics: {self.topics}'
            )
            self.app.run()

        except Exception as e:
            Logger.base.error(f'{self.consumer_tag} Failed to start Quix Streams Consumer: {e}')
            raise

    @Logger.io
    async def stop(self):
        """åœæ­¢ Quix Streams æ¶ˆè²»è€…"""
        self.running = False
        # Quix Streams æœƒè‡ªå‹•è™•ç†è³‡æºæ¸…ç†
        Logger.base.info(f'{self.consumer_tag} Quix Streams Consumer stopped')

    def _deserialize_message(self, message) -> Dict[str, Any]:
        """
        ååºåˆ—åŒ– Protobuf æ¶ˆæ¯ (Quix Streams ç‰ˆæœ¬) - æ”¯æ´æ··åˆæ ¼å¼

        ã€å¥å£¯çš„ååºåˆ—åŒ–ç­–ç•¥ã€‘
        1. é¦–å…ˆå˜—è©¦ Protobuf å°è±¡è™•ç†
        2. è™•ç† Protobuf ä¸­çš„ data å­—æ®µ (ä½¿ç”¨ orjson ååºåˆ—åŒ–)
        3. æ‰€æœ‰å¤±æ•—å‰‡è·³éè©²æ¶ˆæ¯é¿å…é˜»å¡
        """

        try:
            Logger.base.info(f'ğŸ” [CONSUMER] æ”¶åˆ°æ¶ˆæ¯é€²è¡Œååºåˆ—åŒ–: {type(message)}')

            # Step 1: å–å‡º value
            raw_value = message.value if hasattr(message, 'value') else message

            # Step 2: å˜—è©¦ Protobuf
            try:
                event_data = MessageToDict(
                    raw_value,
                    preserving_proto_field_name=True,  # ä¿ç•™åŸå§‹å­—æ®µå
                )
                Logger.base.info(f'ğŸ‰ [CONSUMER] Protobuf ååºåˆ—åŒ–å®Œæˆ: {event_data}')

                # Step 3: è™•ç† Protobuf ä¸­çš„ data å­—æ®µ (ä½¿ç”¨ orjson ååºåˆ—åŒ–)
                if 'data' in event_data and event_data['data']:
                    data_bytes = base64.b64decode(
                        event_data['data']
                    )  # data å­—æ®µæ˜¯ base64 ç·¨ç¢¼çš„ bytesï¼Œéœ€è¦å…ˆè§£ç¢¼å†ç”¨ orjson è§£æ
                    parsed_data = orjson.loads(data_bytes)
                    event_data['data'] = parsed_data
                    Logger.base.info(f'âœ… [CONSUMER] orjson ååºåˆ—åŒ– data å­—æ®µæˆåŠŸ: {parsed_data}')

                return event_data
            except Exception as e:
                Logger.base.critical(f'âš ï¸ Protobuf ååºåˆ—åŒ–å¤±æ•—: {e}')
                Logger.base.critical(f'Unrecognized message format: {type(raw_value)}, skipping...')
                return {'event_type': None, 'error': 'Unrecognized message format'}

        except Exception as e:
            Logger.base.error(f'Critical deserialization error: {e}')
            return {'event_type': None, 'error': str(e)}

    def _log_before_filter(self, event_data: Dict[str, Any]) -> Dict[str, Any]:
        Logger.base.info(f'ğŸ” [CONSUMER] éæ¿¾å‰æª¢æŸ¥: {event_data}')
        return event_data

    def _run_async_safely(self, coro):
        """å®‰å…¨åœ°åœ¨åŒæ­¥ä¸Šä¸‹æ–‡ä¸­é‹è¡Œç•°æ­¥å‡½æ•¸"""
        from concurrent.futures import ThreadPoolExecutor

        try:
            # æª¢æŸ¥æ˜¯å¦åœ¨ç•°æ­¥ä¸Šä¸‹æ–‡ä¸­
            sniffio.current_async_library()

            # å¦‚æœåœ¨ç•°æ­¥ä¸Šä¸‹æ–‡ä¸­ï¼Œä½¿ç”¨ ThreadPoolExecutor åœ¨æ–°ç·šç¨‹ä¸­é‹è¡Œ
            def run_in_thread():
                async def wrapper():
                    return await coro

                return anyio.run(wrapper)

            with ThreadPoolExecutor() as executor:
                future = executor.submit(run_in_thread)
                return future.result()

        except sniffio.AsyncLibraryNotFoundError:
            # æ²’æœ‰é‹è¡Œçš„ç•°æ­¥åº«ï¼Œç›´æ¥ä½¿ç”¨ anyio.run
            async def wrapper():
                return await coro

            return anyio.run(wrapper)

    @Logger.io
    def _process_event_with_handlers_sync(self, event_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç›´æ¥åŒæ­¥è™•ç†äº‹ä»¶ - èª¿ç”¨ç•°æ­¥ gateway

        ã€æœ€ç›´æ¥çš„è§£æ±ºæ–¹æ¡ˆã€‘
        ç›´æ¥èª¿ç”¨ gateway çš„ç•°æ­¥æ–¹æ³•ï¼Œç”¨ anyio åŸ·è¡Œ
        """
        event_type = event_data.get('event_type')
        Logger.base.info(f'ğŸš€ [CONSUMER] è™•ç†äº‹ä»¶: {event_type}')

        try:
            # ç›´æ¥è™•ç† BookingCreated äº‹ä»¶
            if event_type == 'BookingCreated':
                Logger.base.info('ğŸ“¨ [CONSUMER] è™•ç† BookingCreated äº‹ä»¶')

                # æ‰¾åˆ° EventTicketingEventConsumer
                ticketing_handler = None
                for handler in self.handlers:
                    if type(handler).__name__ == 'EventTicketingEventConsumer':
                        ticketing_handler = handler
                        break

                if ticketing_handler:
                    Logger.base.info('âœ… [CONSUMER] æ‰¾åˆ° EventTicketingEventConsumerï¼Œé–‹å§‹è™•ç†')

                    # å¾ handler ä¸­ç²å– gateway
                    gateway: EventTicketingMqGateway = ticketing_handler.event_ticketing_gateway
                    Logger.base.info(f'ğŸ“¡ [CONSUMER] ç²å–åˆ° ã€{gateway}')

                    # å‰µå»ºå‘½ä»¤

                    parsed_data = event_data if isinstance(event_data, dict) else {}
                    Logger.base.info(f'ğŸ“‹ [CONSUMER] äº‹ä»¶æ•¸æ“š: {parsed_data}')
                    command = BookingCreatedCommand.from_event_data(event_data=parsed_data)
                    Logger.base.info(f'ğŸ¯ [CONSUMER] è™•ç†é è¨‚: booking_id={command.booking_id}')

                    # ç›´æ¥èª¿ç”¨ gateway çš„ç•°æ­¥æ–¹æ³•

                    try:
                        # èª¿ç”¨ gateway.handle_booking_created (é€™å€‹æœ¬ä¾†å°±æ˜¯ç•°æ­¥çš„)
                        Logger.base.info('ğŸ”¥ [DEBUG] æº–å‚™èª¿ç”¨ anyio')
                        Logger.base.info(f'ğŸ”¥ [DEBUG] gateway é¡å‹: {type(gateway)}')
                        Logger.base.info(f'ğŸ”¥ [DEBUG] command é¡å‹: {type(command)}')

                        result = self._run_async_safely(gateway.handle_booking_created(command))
                        Logger.base.info('ğŸ”¥ [DEBUG] anyio åŸ·è¡Œå®Œæˆ')
                        Logger.base.info(f'ğŸš€ [CONSUMER] Gateway è™•ç†çµæœ: {result}')
                        Logger.base.info(f'ğŸ”¥ [DEBUG] result é¡å‹: {type(result)}')

                        # æ ¹æ“šçµæœç™¼é€å›æ‡‰
                        if result.is_success:
                            self._run_async_safely(gateway.send_success_response(result))
                            Logger.base.info(
                                f'âœ… [CONSUMER] è™•ç†æˆåŠŸ: booking_id={command.booking_id}'
                            )

                            return {
                                'status': 'processed',
                                'event_type': event_type,
                                'booking_id': command.booking_id,
                                'ticket_ids': result.ticket_ids or [],
                            }
                        else:
                            self._run_async_safely(
                                gateway.send_failure_response(
                                    command.booking_id, result.error_message or 'Unknown error'
                                )
                            )
                            Logger.base.error(f'âŒ [CONSUMER] è™•ç†å¤±æ•—: {result.error_message}')
                            return {
                                'status': 'error',
                                'error': result.error_message,
                                'event_type': event_type,
                            }

                    except Exception as e:
                        Logger.base.error(f'âŒ [CONSUMER] Gateway èª¿ç”¨å¤±æ•—: {e}')
                        return {'status': 'error', 'error': str(e), 'event_type': event_type}

                else:
                    Logger.base.error('âŒ [CONSUMER] æ‰¾ä¸åˆ° EventTicketingEventConsumer')
                    return {'status': 'no_handler', 'event_type': event_type}

            # è™•ç†å…¶ä»–äº‹ä»¶é¡å‹
            else:
                Logger.base.info(f'ğŸ“¨ [CONSUMER] å…¶ä»–äº‹ä»¶é¡å‹: {event_type}')
                return {'status': 'unhandled', 'event_type': event_type}

        except Exception as e:
            Logger.base.error(f'ğŸ’¥ [CONSUMER] è™•ç†äº‹ä»¶å¤±æ•—: {e}')
            import traceback

            Logger.base.error(f'ğŸ’¥ [CONSUMER] è©³ç´°éŒ¯èª¤: {traceback.format_exc()}')
            return {'status': 'error', 'error': str(e), 'event_type': event_type}

    async def _process_event_with_handlers(self, event_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        è™•ç†äº‹ä»¶èˆ‡è™•ç†å™¨è·¯ç”± (ç´”ç•°æ­¥ç‰ˆæœ¬)

        ã€æœ€å°å¯è¡ŒåŸå‰‡ã€‘
        1. åˆ¤æ–·äº‹ä»¶é¡å‹
        2. æ‰¾åˆ°å°æ‡‰çš„ handler
        3. ç›´æ¥åˆ†ç™¼è™•ç†
        4. è¿”å›çµæœ
        """
        event_type = event_data.get('event_type')
        Logger.base.info(f'ğŸš€ [CONSUMER] é–‹å§‹è™•ç†äº‹ä»¶: {event_type}')
        Logger.base.info(f'ğŸ” [CONSUMER] å·²è¨»å†Šçš„è™•ç†å™¨æ•¸é‡: {len(self.handlers)}')

        try:
            # 1. å¿«é€Ÿè·¯ç”±åˆ°æ­£ç¢ºçš„ handler
            target_handler = None
            for i, handler in enumerate(self.handlers):
                handler_name = type(handler).__name__
                Logger.base.info(f'ğŸ” [CONSUMER] æª¢æŸ¥è™•ç†å™¨ {i}: {handler_name}')
                try:
                    # ç›´æ¥èª¿ç”¨ async æ–¹æ³•
                    can_handle = await handler.can_handle(event_type or '')
                    Logger.base.info(
                        f'ğŸ” [CONSUMER] {handler_name}.can_handle("{event_type}") = {can_handle}'
                    )
                    if can_handle:
                        target_handler = handler
                        Logger.base.info(f'âœ… [CONSUMER] æ‰¾åˆ°è™•ç†å™¨: {handler_name}')
                        break
                except Exception as e:
                    Logger.base.error(f'âŒ [CONSUMER] æª¢æŸ¥è™•ç†å™¨ {handler_name} æ™‚å‡ºéŒ¯: {e}')
                    continue

            # 2. å¦‚æœæ²’æ‰¾åˆ° handlerï¼Œç›´æ¥è¿”å›
            if not target_handler:
                Logger.base.warning(f'âš ï¸ [CONSUMER] æ²’æœ‰æ‰¾åˆ°è™•ç†å™¨å°æ‡‰äº‹ä»¶é¡å‹: {event_type}')
                return {'status': 'no_handler', 'event_type': event_type}

            # 3. ç›´æ¥åˆ†ç™¼åˆ° handler è™•ç†
            Logger.base.info(f'ğŸ¯ [CONSUMER] åˆ†ç™¼åˆ° handler: {type(target_handler).__name__}')

            # ç›´æ¥èª¿ç”¨ async æ–¹æ³•
            result = await target_handler.handle(event_data)

            Logger.base.info(f'âœ… [CONSUMER] è™•ç†å®Œæˆ: {result}')
            return {'status': 'processed', 'result': result, 'event_type': event_type}

        except Exception as e:
            Logger.base.error(f'ğŸ’¥ [CONSUMER] è™•ç†äº‹ä»¶å¤±æ•—: {e}')
            return {'status': 'error', 'error': str(e), 'event_type': event_type}


# === å…¨å±€æ¶ˆè²»è€…ç®¡ç† ===
# ã€MVPåŸå‰‡ã€‘ä½¿ç”¨å…¨å±€å¯¦ä¾‹ç®¡ç†ï¼Œé¿å…é‡è¤‡å‰µå»ºæ¶ˆè²»è€…

_unified_consumer: Optional[UnifiedEventConsumer] = None


@Logger.io
async def start_unified_consumer(
    topics: List[str], handlers: List[EventHandler], consumer_tag: str = '[CONSUMER]'
) -> None:
    """
    å•Ÿå‹•çµ±ä¸€çš„äº‹ä»¶æ¶ˆè²»è€…

    ã€MVPå•Ÿå‹•æ¥å£ã€‘é€™æ˜¯å¤–éƒ¨å•Ÿå‹•æ¶ˆè²»è€…çš„çµ±ä¸€å…¥å£

    Args:
        topics: è¦ç›£è½çš„Kafkaä¸»é¡Œåˆ—è¡¨
        handlers: äº‹ä»¶è™•ç†å™¨åˆ—è¡¨ï¼ˆæ¯å€‹æœå‹™æä¾›è‡ªå·±çš„è™•ç†å™¨ï¼‰
        consumer_tag: æ¶ˆè²»è€…æ¨™è­˜ï¼Œç”¨æ–¼æ—¥å¿—è¿½è¹¤

    ä½¿ç”¨ä¾‹å­ï¼š
    ```python
    topics = ["ticketing-booking-request", "ticketing-booking-response"]
    handlers = [BookingEventConsumer(), TicketingEventConsumer()]
    await start_unified_consumer(topics, handlers)
    ```
    """
    global _unified_consumer

    if _unified_consumer is None:
        # å‰µå»ºçµ±ä¸€æ¶ˆè²»è€…å¯¦ä¾‹
        _unified_consumer = UnifiedEventConsumer(topics, consumer_tag=consumer_tag)

        # è¨»å†Šæ‰€æœ‰äº‹ä»¶è™•ç†å™¨
        for handler in handlers:
            _unified_consumer.register_handler(handler)

    # å•Ÿå‹•æ¶ˆè²»è€…
    await _unified_consumer.start()


@Logger.io
async def stop_unified_consumer() -> None:
    """
    åœæ­¢çµ±ä¸€çš„äº‹ä»¶æ¶ˆè²»è€…

    ã€MVPåœæ­¢æ¥å£ã€‘æ¸…ç†å…¨å±€æ¶ˆè²»è€…è³‡æº
    """
    global _unified_consumer
    if _unified_consumer:
        await _unified_consumer.stop()
        _unified_consumer = None


@Logger.io
def get_unified_consumer() -> Optional[UnifiedEventConsumer]:
    """
    ç²å–çµ±ä¸€çš„æ¶ˆè²»è€…å¯¦ä¾‹

    ã€MVPæŸ¥è©¢æ¥å£ã€‘ç”¨æ–¼ç›£æ§å’Œèª¿è©¦
    """
    global _unified_consumer
    return _unified_consumer
